---
title: "Untitled"
output: html_document
---


```{r}

library("e1071")
library("caret")
library("glmnet")
#library("dbplyr")
library("splines")
library("mcmcplots")
library(class);
```

```{r}
train <- read.table(file="train.csv", sep = ",");
train_38 <- subset(train, train[,1]==3 | train[,1]==8);

```
```{r}
test <- read.table(file="test.csv", sep = ",");
test_38 <- subset(test, test[,1]==3 | test[,1]==8);
dim(test_38) ##345 257
```
```{r}
dim(train_38); ## 1376 257
```


```{r}

printrows <- train_38[30:35,]
printrows   
```
```{r}
sum(train_38[,1] == 3);
```
```{r}
sum(train_38[,1] == 8);
```



```{r}
## To see the letter picture of the 5-th row by changing the row observation to a matrix
rowindex = 600; ## You can try other "rowindex" values to see other rows
train_38[rowindex,1];
Xval = t(matrix(data.matrix(train_38[,-1])[rowindex,],byrow=TRUE,16,16)[16:1,]);
image(Xval,col=gray(0:1),axes=FALSE) ## Also try "col=gray(0:32/32)"
```

```{r}
## To see the letter picture of the 5-th row by changing the row observation to a matrix
rowindex = 656; ## You can try other "rowindex" values to see other rows
train_38[rowindex,1];
Xval = t(matrix(data.matrix(train_38[,-1])[rowindex,],byrow=TRUE,16,16)[16:1,]);
image(Xval,col=gray(0:1),axes=FALSE) ## Also try "col=gray(0:32/32)"
```




(5) (Cross-Validation.) The above steps are sucient when both training and testing data sets are very
large. However, for relatively small data sets, one may want to do further to assess the robustness of each
approach. One general approach is Monte Carlo Cross Validation algorithm


```{r}
### The following R code might be useful for part (5), and please feel free to modify it.
data_38 = rbind(train_38, test_38) ### combine to a full data set
n1 = 1200; # training set sample size
n2= 332; # testing set sample size
n = dim(data_38)[1]; ## the total sample size
set.seed(7406); ### set the seed for randomization
### Initialize the TE values for all models in all $B=100$ loops
B= 700; ### number of loops
TEALL = NULL; ### Final TE values
```
```{r}
for (b in 1:B){
### randomly select n1 observations as a new training subset in each loop
flag <- sort(sample(1:n, n1));
traintempset <- data_38[flag,];
testtempset <- data_38[-flag,];
### you can write your own R code here to first fit each model to "zip27traintempset"
### then get the testing error (TE) values on the testing data "zip27testtempset"
### Suppose you save the TE values for these 9 methods (1 linear regression and 8 KNN) as
### te0, te1, te2, te3, te4, te5, te6, te7, te8 respectively, within this loop
### Then you can save these $9$ Testing Error values by using the R code
###

xnew2 <- testtempset[,-1];
# KNN k=1
kk <- 1;
ypred.knnset.1.test <- knn(traintempset[,-1], xnew2, traintempset[,1], k=kk);
te1 <- mean( ypred.knnset.1.test != testtempset[,1])

# KNN k=3
kk <- 3;
ypred.knnset.3.test <- knn(traintempset[,-1], xnew2, traintempset[,1], k=kk);
te2 <- mean( ypred.knnset.3.test != testtempset[,1])

# KNN k=5
kk <- 5;
ypred.knnset.5.test <- knn(traintempset[,-1], xnew2, traintempset[,1], k=kk);
te3 <- mean( ypred.knnset.5.test != testtempset[,1])

# KNN k=7
kk <- 7;
ypred.knnset.7.test <- knn(traintempset[,-1], xnew2,traintempset[,1], k=kk);
te4 <- mean( ypred.knnset.7.test != testtempset[,1])

# KNN k=9
kk <- 9;
ypred.knnset.9.test <- knn(traintempset[,-1], xnew2, traintempset[,1], k=kk);
te5 <- mean( ypred.knnset.9.test != testtempset[,1])

# KNN k=11
kk <- 11;
ypred.knnset.11.test <- knn(traintempset[,-1], xnew2, traintempset[,1], k=kk);
te6 <- mean( ypred.knnset.11.test != testtempset[,1])

# KNN k=13
kk <- 13;
ypred.knnset.13.test <- knn(traintempset[,-1], xnew2,traintempset[,1], k=kk);
te7 <- mean( ypred.knnset.13.test !=testtempset[,1])

# KNN k=15
kk <- 15;
ypred.knnset.15.test <- knn(traintempset[,-1], xnew2, traintempset[,1], k=kk);
te8 <- mean( ypred.knnset.15.test != testtempset[,1])

TEALL = rbind( TEALL, cbind( te1, te2, te3, te4, te5, te6, te7, te8) );
}
```

```{r}
dim(TEALL); ### This should be a Bx9 matrices
### if you want, you can change the column name of TEALL
colnames(TEALL) <- c( "KNN1", "KNN3", "KNN5", "KNN7",
"KNN9", "KNN11", "KNN13", "KNN15");
## You can report the sample mean and sample variances for the five models
apply(TEALL, 2, mean);
apply(TEALL, 2, var);
```

```{r}

boxplot(TEALL,
data=airquality,
main="Error boxplot for each model obtained from CV, B=700",
xlab="Model",
ylab="CV Error",
col="orange",
border="brown"

)
```


```{r}
lm_1000_error <- subset(TEALL , colnames(TEALL) == c('LR'))
rmeanplot(TEALL, style="plain")

```

